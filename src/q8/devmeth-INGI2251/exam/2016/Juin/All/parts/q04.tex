\clearpage{}
\section{Discuss cost estimation, when it should be done and what it should
estimate. Describe and compare expert judgment, cost matrix (Wolverton),
algorithmic (COCOMO) and machine learning methods. Detail the three stages
of the COCOMO II method. Define risk, risk impact and risk exposure. Discuss
strategies for risk reduction.}

\subsection{Cost estimation}

\subsubsection{When?}

Estimating project costs has to be done as early as possible (but imprecise at the start) and
it should be done repeatedly.

\subsubsection{What?}

\begin{itemize}
    \item Facilities: hardware, space, furniture, telephone,\ldots
    \item Staff (effort): the biggest component and the greatest degree of uncertainty $\rightarrow$ depends on work style, organization, skills, training,\ldots
    \item Methods and tools
\end{itemize}

\subsection{Methods comparison}

\begin{table}[!ht]
    \begin{tabular}{p{0.17\linewidth}p{0.75\linewidth}}
        \toprule
        Expert judgment & \begin{minipage}{\linewidth}\begin{itemize}
                            \item Based on analogies with past projects
                            \item Beta-probability distribution: $(x+4y+z)/6$ with
                                \begin{itemize}
                                    \item x: optimist estimates
                                    \item y: most likely estimates
                                    \item z: pessimist estimates
                                \end{itemize}
                            \item Delphi technique (use average of \enquote{secret}
                            estimates)
                          \end{itemize}
                          Subjective, simplistic\end{minipage} \\
        \midrule
        Cost matrix (Wolverton) &   $s/LOC$ as a function of type of software,
                                    novelty, difficulty \\
        \midrule
        Algorithmic (COCOMO) & \begin{minipage}{\linewidth}\begin{itemize}
                                    \item $E = b {S}^{c}$
                                    \item $b,c$: calibrated on past projects
                                    \item $S$: estimated size of the system (LOC)
                                    \item $E$: estimation in man-months
                               \end{itemize}\end{minipage} \\
        \midrule
        Machine learning &  \begin{minipage}{\linewidth}\begin{itemize}
                                \item Case-based reasoning (use data from past projects)
                                \item Four steps:
                                    \begin{enumerate}
                                        \item User identifies problem as a case
                                        \item System retrieves similar case from a
                                        repository
                                        \item System reuse knowledge from previous
                                        case
                                        \item System suggests a solution for the
                                        new case
                                    \end{enumerate}
                            \end{itemize}
                            But hard to define the problem as a case and
                            determine similarity.\end{minipage} \\
        \bottomrule
    \end{tabular}
    \caption{Methods comparison}
\end{table}

No model works for all types of development.

\subsection{Three stages of the COCOMO II method}

\subsubsection{Application points}:

Object: report, program component etc\ldots \newline
Object points (numerical value) depend of complexity. \newline
Application points: Sum of Object points

\subsubsection{Stages:}

\begin{enumerate}
    \item Application Composition:
        \subitem{} Prototyping stage
        \subitem{} $S$ in application points
        \subitem{} $E = b \times S = NOP / PROD$
        \subitem{} $1 / b$ = productivity (ex: developer experience and skills)
        \subitem{} $S = NOP$ = application points

    \begin{framed}
        In stage 2 and 3:
        $$E = b \times S^{c} \times m({x}_{1},\ldots, {x}_{n})$$
        $c$ between $0.91$ and $1.23$ depend of novelty, team cohesion,\ldots
    \end{framed}
    \item Early Design:
        \subitem{} Architectural design stage
        \subitem{} S in function points
        \subitem{} UFP (unadjusted function points) Sum of application components.
        \subitem{} $S = FP = UFP \times TCF$ (technical complexity factor)
    \item Postarchitecture:
        \subitem{} Development stage
        \subitem{} S in lines of code
\end{enumerate}

\subsection{Risk definitions}

\begin{description}
    \item[Risk] An unwanted event that has negative consequences.
    \item[Risk impact] The loss associated with the event. [\$, man-month]
    \item[Risk probability] The likelihood that the risk will occur [0\ldots1]
    \item[Risk exposure] $(\textrm{risk probability}) \times (\textrm{risk impact})$ [\$, man-month]
\end{description}

\subsection{Strategies for risk reduction}

\begin{description}
    \item[Risk avoidance] Change requirements, add resources, training,\ldots
    \item[Risk transfer] Transfer to another system, partnering, buy insurance
    \item[Risk acceptance] Accept and control the risk, contingency plans
\end{description}

To aid decision making about risk reduction, we must take into account the cost of reducing
the risk. We call risk leverage the difference in risk exposure divided by the cost of reducing
the risk. In other words, risk reduction leverage is:

$$
    (E - E')/C
$$

with

$E, E'$ = risk exposure before and after reduction

$C$ = cost of risk reduction
