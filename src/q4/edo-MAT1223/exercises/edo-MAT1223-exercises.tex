\documentclass[fr,license=none]{../../../eplexercises}

\usepackage{wasysym}
\usepackage{bm}

\hypertitle{Equations différentielles ordinaires}{4}{MAT}{1223}
{Benoît Legat \and Julien Vaes}
{Jean Van Schaftingen}

Les corrections de ce correctif seront soumises au prof d'EDO pour
être rajoutée dans le syllabus de l'an prochain.
En attendant, elles sont publiées par ce biais ci.
Vous êtes bien entendu invités à en ajouter.

\section{Systèmes linéaires à coefficients constants}

\subsection*{1.18}
\begin{enumerate}
  \item[a)]
    \begin{equation}
      w''(t)-4w'(t)-5w(t)=f(t)
    \end{equation}

    Posons
    \begin{equation}
      \bm{u}(t) = \left(
        \begin{matrix}
          w(t)\\w'(t)
        \end{matrix}
      \right)
    \end{equation}
    Nous avons le système suivant
    \begin{equation}
      \bm{u}'(t) = \left(
        \begin{matrix}
          0&1 \\
          4&5 \\
        \end{matrix}
      \right) \cdot \bm{u}+\left(
        \begin{matrix}
          0 \\
          f(t) \\
        \end{matrix}
      \right)
    \end{equation}

    Trouvons donc l'expression de $e^{tA}$. Nous savons que $\frac{de^{tA}}{dt} = Ae^{tA}$. Nous savons aussi que
    \begin{equation}
      e^{0A} = I
    \end{equation}

    Posons
    \begin{equation}
      e^{tA}= \left(
        \begin{matrix}
          a&b \\
          c&d \\
        \end{matrix}
      \right)
    \end{equation}
    Pour trouver $e^{tA}$ nous devons donc résoudre
    \begin{eqnarray*}
      \left(
        \begin{matrix}
          a'&b' \\
          c'&d' \\
        \end{matrix}
      \right) &=&\left(
        \begin{matrix}
          0&1 \\
          4&5 \\
        \end{matrix}
      \right) \cdot\left( \begin{matrix}
          a&b \\
          c&d \\
        \end{matrix}
      \right)\\
      &=& \left(
      \begin{matrix}
        c&d \\
        4a+5c&4b+5d \\
      \end{matrix}
    \right)
  \end{eqnarray*}

  Nous avons donc que
  \begin{equation}
    c''(t) -5c'(t) -4c(t)=0
  \end{equation}

  Donc
  \begin{equation}
    c(t) = C_1 e^{\frac{5+\sqrt{41}}{2}} + C_2 e^{\frac{5-\sqrt{41}}{2}}
  \end{equation}



\item[b)]
\end{enumerate}


\section{Systèmes linéaires à coefficients variables}

\subsection*{2.15}
Nous avons l'équation suivante:
\begin{equation} \label{eq_2.15_1}
u''(t) = \frac{u'(t)}{t} + \left( 1 - \frac{3}{t} \right) \cdot u(t)  \hspace{1 cm } t>0
\end{equation}

ainsi qu'une solution
\begin{equation}
u_1(t) = t^2 e^{-t}
\end{equation}

Posons
\begin{eqnarray}
\bm{u_1}(t) &=& (u_1(t)  \hspace{0.3cm}u_1'(t))^T\\
&=&(t^2 e^{-t} \hspace{0.5cm} 2t e^{-t} -t^2 e^{-t} )^T
\end{eqnarray}



Nous pouvons mettre ce problème sous le forme matricielle:
\begin{eqnarray*}
\bm{v}' &=& \bm{A}[\bm{v}]\\
\bm{v}'&=&\left(
\begin {matrix}
 0&1 \\
 1-\frac{3}{t}&\frac{1}{t} \\
\end{matrix}
\right) \cdot \bm{v}
\end{eqnarray*}

Nous savons que la seconde solution de l'équation \ref{eq_2.15_1} est de la forme
\begin{equation}
\bm{u_2}(t) = \alpha(t) \bm{u_1}(t) + \bm{w}(t)
\end{equation}

où nous avons un vecteur $\bm{e}$ tel que
\begin{eqnarray*}
(\bm{e}|\bm{u_1}(t)) &\neq& 0\\
(\bm{e}|\bm{w}(t))&=&0
\end{eqnarray*}

Prenons $\bm{e}=(1\hspace{0.3cm}0)^T$ nous avons donc que $\bm{w}(t) = (0\hspace{0.3cm}\beta(t))^T$.

Nous savons que la dérivée de $\bm{u_2}$ doit être égale à sa dérivée via le système matriciel. Nous obtenons donc le système suivant:
\begin{eqnarray}
\bm{A}[\alpha(t) \bm{u_1}(t)]+\bm{A}[(0 \hspace{0.3 cm} \beta(t))^T] &=& \bm{A}[\alpha(t)\bm{u_1}(t)] + \alpha'(t)\bm{u_1}(t)+\beta'(t)\cdot (0 \hspace{0.3 cm} 1)^T\\
\bm{A}[(0 \hspace{0.3 cm} \beta(t))^T] &=&  \alpha'(t)\bm{u_1}(t)+\beta'(t)\cdot (0 \hspace{0.3 cm} 1)^T
\end{eqnarray}

 Ce qui donne les deux équations suivantes
 \begin{eqnarray}
\beta(t)&=&\alpha'(t)t^2e^{-t}\\
\frac{\beta(t)}{t}&=&\alpha'(t)\cdot \left( 2t e^{-t} -t^2 e^{-t}  \right) +\beta'(t)
\end{eqnarray}

On obtient donc que
\begin{equation}
\alpha'(t) = \frac{\beta(t)}{t^2 e^{-t}} \label{eq_2.15_ab}
\end{equation}

En remplaçant cela dans la seconde équation du système, nous obtenons:
\begin{eqnarray*}
\frac{\beta(t)}{t}&=&\frac{\beta(t)}{t^2 e^{-t}}\cdot \left( 2t e^{-t} -t^2 e^{-t}  \right) +\beta'(t)\\
\frac{\beta(t)}{t}&=&\frac{\beta(t)}{t}\cdot \left( 2-t  \right) +\beta'(t)\\
0&=& \frac{\beta(t)}{t}\cdot \left( 1-t  \right)+\beta'(t)\\
\frac{\beta'(t)}{\beta(t)}&=&\frac{t-1}{t} = 1-\frac{1}{t}\\
\int_1^t \frac{\beta'(t)}{\beta(t)} &=& \int_1^t1-\frac{1}{t}\\
\ln{\beta(t)} &=& t-\ln t - 1
\end{eqnarray*}
On peut supprimer les constantes car après dérivation elles disparaissent.
On obtient donc que
\begin{equation}
\beta(t) = \frac{e^{t}}{t}
\end{equation}

De part l'équation \ref{eq_2.15_ab}, on trouve
\begin{equation}
\alpha(t)= \left( \int_{t_0}^t \frac{e^{2t}}{t^3} \right)
\end{equation}

On trouve donc comme seconde solution:
\begin{equation}
v_2(t) = \left( \int_{t_0}^t \frac{e^{2t}}{t^3} \right) \cdot t^2 e^{-t}
\end{equation}


\section{Systèmes d'équations différentielles ordinaires non linéaires}

\subsection*{3.1}
Supposons sans perte de généralité que $x \leq y$ pour que $[x,y]$ ait du sens
\begin{enumerate}
  \item Lipchitzienne avec $L = 1$ car, comme
    $|\sin t| \leq 1$ $\forall t \in \mathbb{R}$,
    \[ |f(t,y) - f(t,x)| \leq |\cos y - \cos x| \]
    et par Taylor, $\exists c \in [x,y]$ tel que
    \[ \cos y = \cos x - \sin c (y - x) \]
    donc
    \[ |f(t,y) - f(t,x)| \leq |\sin c| \cdot |y - x| \leq |y - x|. \]
  \item Pas lipschitzienne car
    \[ |f(t,y) - f(t,x)| = |t|\cdot||y| - |x|| \]
    et comme $L$ ne peut pas dépendre de $t$ et que $|t|$ peut être aussi
    grand que l'on veut, il n'existe pas de constante $L$.
  \item Lipschitzienne avec $L = 1$ car
    \[ |f(t,y) - f(t,x)| = ||y| - |x|| \leq |y - x|. \]
  \item Lipschitzienne avec $L = 1$ car
    \[ |f(t,y) - f(t,x)| = |t|\cdot||y| - |x|| \leq \cdot |y - x|. \]
  \item $\sqrt{t}$ défini pour tout $t \in [-1,1]$ ?
  \item Pas lipschitzienne avec car
    \[ |f(t,y) - f(t,x)| = |t|\cdot|\sqrt{y} - \sqrt{x}| \]
    et par Taylor, $\exists c \in [x,y]$ tel que
    \[ \sqrt{y} = \sqrt{x} + \frac{1}{2\sqrt{c}}(y-x) \]
    d'où
    \[ |f(t,y) - f(t,x)| = |t|\frac{1}{2\sqrt{c}}|y-x|. \]
    En prenant $t \neq 0$ et en faisant tendre $x$ et $y$ vers 0,
    $\frac{1}{c}$ devient aussi grand que l'on veut donc $L$ n'existe pas.
  \item Idem, ne serait-ce pas $f:[-1,1]\times[1,\infty[$ ?
  \item Lipschitzienne avec $L = 1$ car $\forall t \in [0,1]$,
    \[ |f(t,y) - f(t,x)| = ||y| - |x|| \leq |y - x| \]
    et $\forall t \in [-1,0[$,
    \[ |f(t,y) - f(t,x)| = |-|y| + |x|| \leq |y - x|. \]
  \item Lipchitzienne avec $L = 1$ car, par Taylor,
    $\exists c \in [x,y]$ tel que
    \[ \arctan y = \arctan x + \frac{1}{1+c^2} (y - x) \]
    donc
    \[ |f(t,y) - f(t,x)| \leq \frac{1}{1+c^2} \cdot |y - x| \leq |y - x|. \]
\end{enumerate}

\subsection*{3.6}
\begin{enumerate}
  \item Oui, par l'unicité globale car comme
    $f(t,x) = 0$ est de classe $C^1$ en espace,
    $f$ et localement lipschitzien.
  \item Oui, par l'unicité globale car comme
    $f(t,x) = x^2$ est de classe $C^1$ en espace,
    $f$ et localement lipschitzien.
  \item Non, en intégrant on obtient $u(t)\ln u(t) + u(t) = t$.
    On trouve deux solutions à ça qui sont ?
  \item Oui, par l'unicité globale car comme
    $f(t,x) = \sin(x)$ est de classe $C^1$ en espace,
    $f$ est localement lipschitzien.
  \item Non, la dérivée en espace de $f(t,x) = \sqrt[3]{x^2}$ est
    $D_x f(t,x) = \frac{1}{3\sqrt[3]{x}}$ qui est continue sauf en $x = 0$.
    Ça ne nous permet tout de même pas de conclure car c'est suffisant à
    l'unicité mais pas nécessaire.
    On pourrait croire qu'elle est unique car en intégrant, on trouve
    $3\sqrt[3]{u(t)} = t$ qui ne comporte comme unique solution
    $u(t) = \frac{t^3}{27}$ mais ce faisant, on divise par $u(t)$ et
    $u(t) = 0$ pour tout $t$ est aussi une solution.
\end{enumerate}

\subsection*{3.16}
\begin{enumerate}
  \item
  \item
  \item
  \item
  \item
  \item
  \item
  \item
  \item
\end{enumerate}

\subsection*{3.18}
\begin{enumerate}
  \item Oui. Commençons par prouver qu'il existe une courbe intégrale maximale.
    On peut réécrir le problème comme suit
    \begin{align*}
      \begin{pmatrix}
        u'(t)\\
        v'(t)
      \end{pmatrix} & =
      \begin{pmatrix}
        v(t)\\
        \sin(u(t))
      \end{pmatrix}.
    \end{align*}

    Soit $f:\mathbb{R}\times\mathbb{R}^2\to\mathbb{R}^2:
    (t,u,v)\mapsto(v,\sin u)$, on voit que $f$ est continue et que
    $f$ est localement lipschitzienne car
    \[ D_uf(t,u,v) =
    \begin{pmatrix}
      0 & 1\\
      \cos u & 0
    \end{pmatrix} \]
    est continue.

    Par le théorème d'existence maximale, il existe donc une courbe intégrale
    maximale et elle est unique.

    Soit $u:I\to\mathbb{R}$ cette courbe intégrale maximale telle que
    $u(0) = u_0$ et $v(0) = v_0$, montrons que $I = \mathbb{R}$.
    Soit $u$ une courbe intégrale maximale.
    On remarque que $|u''(t)| \leq 1$.
    Du coup,
    \begin{align*}
      |u'(t) - v_0| & \leq |t - t_0|\\
      |u'(t)| & \leq |v_0| + |t - t_0|\\
      |u(t) - u_0| & \leq |v_0|\cdot|t - t_0| + \frac{|t - t_0|^2}{2}\\
      |u(t)| & \leq |u_0| + |v_0|\cdot|t - t_0| + \frac{|t - t_0|^2}{2}.
    \end{align*}
    Soit $T > 0$. Considérons
    \[ K_T = \{(t,u) \in \mathbb{R}^2|
    t \in [t_0-T,t_0+T] \land |u| \leq
    |u_0| + |v_0|\cdot|t - t_0| + \frac{|t - t_0|^2}{2}\}. \]
    On remarque que $K_T$ est compact et comme $u$ est une courbe intégrale
    maximale,
    \begin{align*}
      \sup\{t \in I : (t,u(t)) \in K_T\} & \in I\\
      \inf\{t \in I : (t,u(t)) \in K_T\} & \in I
    \end{align*}
    or, par construction de $K_T$,
    \begin{align*}
      \sup\{t \in I : (t,u(t)) \in K_T\} & = t_0 + T\\
      \inf\{t \in I : (t,u(t)) \in K_T\} & = t_0 - T.
    \end{align*}
    Donc $[t_0-T;t_0+T] \subseteq I$.
    Puisque ceci est vrai $\forall T > 0$, $I = \mathbb{R}$.
  \item
    Idem \smiley
  \item
    Commençons par prouver qu'il existe une courbe intégrale maximale
    et qu'elle est unique.
    En effet, si on montre que pour certains $u_0,v_0$, une courbe intégrale
    n'est pas maximale, si on ne sait pas qu'elle est unique,
    on ne prouve pas qu'il y en a pas pour ces $u_0,v_0$
    définis sur $\mathbb{R}$.
    On peut réécrir le problème comme suit
    \begin{align*}
      \begin{pmatrix}
        u'(t)\\
        v'(t)
      \end{pmatrix} & =
      \begin{pmatrix}
        v(t)\\
        u(t)^3
      \end{pmatrix}.
    \end{align*}

    Soit $f:\mathbb{R}\times\mathbb{R}^2\to\mathbb{R}^2:
    (t,u,v)\mapsto(v,\sin u)$, on voit que $f$ est continue et que
    $f$ est localement lipschitzienne car
    \[ D_uf(t,u,v) =
      \begin{pmatrix}
        0 & 1\\
        3u^2 & 0
    \end{pmatrix} \]
    est continue.

    Par le théorème d'existence maximale, il existe donc une courbe intégrale
    maximale et elle est unique.

    Soit $u:I\to\mathbb{R}$ cette courbe intégrale maximale pour
    $(u_0,v_0) = (-\sqrt{2},-\sqrt{2})$.

    On remarque que $\frac{\sqrt{2}}{t-1}$ est solution et que cette solution
    est maximale sur $I = ]-\infty,1[$.
    Comme on a montré que la solution est unique,
    il n'existe pas de courbe intégrale maximale définie sur tout $\mathbb{R}$
    pour $(u_0,v_0) = (-\sqrt{2},-\sqrt{2})$.
  \item
    Pour résoudre cet exercice, il faut un peu d'intuition.
    Commençons donc par observer le comportement d'une courbe intégrale.
    On voit que la dérivée seconde est de signe contraire de $u$.
    Quand $u$ devient positif, sa dérivée va donc diminuer et $u$ va
    augementer jusqu'à ce que sa dérivée soit nulle.
    $u$ va alors diminuer et sa dérivée va augmenter jusqu'à ce que $u$ soit
    nul.
    Ça fait fort penser à une sinusoïde.
    En effet, l'équation ressemble à celle du mouvement harmonique
    $u''(t) = -ku(t)$ avec $k > 0$.
    On peut prouver que le mouvement harmonique n'explose pas en montrant
    que la somme entre l'énergie cinétique et l'énergie potentielle est
    constante.
    Inspirons nous de cette méthode et prouvons qu'une quantité
    $Au'(t)^a + Bu(t)^b$ est constant.
    D'où on trouve $(A,a,B,b) = (2,2,1,4)$.
    En effet,
    \[ (2u'(t)^2 + u(t)^4)' = -4u'(t)u^3(t) + 4u(t)^3u'(t) = 0. \]
    Comme $2u'(t)^2 \leq 0$, on sait que pour tout $t$,
    \[ |u(t)| \leq \sqrt[4]{2v_0^2 + u_0^4}. \]

    Maintenant qu'on a l'intuition, prouvons qu'il existe une courbe
    maximale pour chaque $u_0,v_0$.
    Pour cela, montrons que
    $f:\mathbb{R}^2 \to \mathbb{R}^2:(x_1,x_2) \mapsto (x_2,-x_1^3)$
    est continue et localement lipschitzien ce qui est assuré par le fait
    que
    \[ Df(x_1,x_2) =
      \begin{pmatrix}
        0 & 1\\
        -3x_1^2 & 0
      \end{pmatrix}.
    \]
    est continue.
    On sait maintenant en plus qu'elle est unique.

    Montrons alors que cette courbe intégrale maximale $u:I\to\mathbb{R}$
    est définie sur $I = \mathbb{R}$.
    Soit $T > 0$, définissons le compact
    \[ K_T = \{(t,u(t)) \in \mathbb{R}^2
    | t \in [-T,T] \land |u(t)| \leq \sqrt[4]{2v_0^2 + u_0^4}\}. \]

    Comme $u$ est maximale, on sait que
    \begin{align*}
      \sup\{t \in I | (t,u(t)) \in K_T\} & \in I\\
      \inf\{t \in I | (t,u(t)) \in K_T\} & \in I
    \end{align*}
    et par construction de $K_T$,
    \begin{align*}
      \sup\{t \in I | (t,u(t)) \in K_T\} & = T\\
      \inf\{t \in I | (t,u(t)) \in K_T\} & = -T
    \end{align*}
    d'où $[-T,T] \subseteq I$.
    Comme c'est vrai pour un $T > 0$ quelconque, on a $I = \mathbb{R}$.
  \item
\end{enumerate}

\section{Stabilité de systèmes d'équations différentielles autonomes}

\subsection*{4.1}
On voit que $f(x_1,x_2) = (-2x_1 + x_1^5 - 3x_2, x_1 + x_2 - x_2^5)$.
On commence par vérifier que $f(0,0) = (0,0)$ et que $f$ est dérivable.
Ensuite, comme
\[ Df(x_1,x_2) =
\begin{pmatrix}
  -2 + 5x_1^4 & -3\\
  1 & 1 - 5x_2^4
\end{pmatrix} \]
est continue, $f$ est localement lipschitzien.

On peut donc déterminer la stabilité de $(0,0)$ à l'aide de
\[ Df(0, 0) =
\begin{pmatrix}
  -2 & -3\\
  1 & 1
\end{pmatrix}. \]
Comme sa trace est négative est que son déterminant est positif,
on sait que les deux valeurs propres ont une partie réelle négative.
Elles valent d'ailleurs $-1/2 \pm i\sqrt{3}/2$.

$(0,0)$ est donc un équilibre asymptotiquement stable et donc aussi
un équilibre stable.

\subsection*{4.2}
On voit que $f(x_1,x_2) = (x_1 + e^{x_2} - \cos(x_2), 3x_1 - x_2 - \sin(x_2))$.
On commence par vérifier que $f(0,0) = (0,0)$ et que $f$ est dérivable.
Ensuite, comme
\[ Df(x_1,x_2) =
\begin{pmatrix}
  1 & e^{x_2} + \sin(x_2)\\
  3 & -1 - \cos(x_2)
\end{pmatrix} \]
est continue, $f$ est localement lipschitzien.

On peut donc déterminer la stabilité de $(0,0)$ à l'aide de
\[ Df(0, 0) =
\begin{pmatrix}
  1 & 1\\
  3 & -2
\end{pmatrix}. \]
Comme sa trace et son déterminant sont négatifs,
on sait qu'une valeur propre a une partie réelle positive,
on sait que les deux valeurs propres ont une partie réelle négative.
Elles valent d'ailleurs $(-1 - \sqrt{21})/2$ et $(-1+\sqrt{21})/2$.

$(0,0)$ est donc un équilibre instable.

\subsection*{4.3}
\begin{enumerate}
  \item
    Par la formule de dérivée en chaine, on a
    \begin{align*}
      \fdif{V(x,y,z)}{t} & = \fpart{V(x,y,z)}{x} x' +
      \fpart{V(x,y,z)}{y} y' + \fpart{V(x,y,z)}{z} z'\\
      & = 2axx' + 2byy' + 2czz'\\
      & = 4axy(z-1) - 2bxy(z-1) - 2cz^4\\
      & = 2(2a-b)xy(z-1) - 2cz^4
    \end{align*}

    En prenant $2a = b$ et $c = 1/2$, on a
    $\fdif{V(x,y,z)}{t} = -z^4 \leq 0$ $\forall x,y,z \in \mathbb{R}^3$.
    $(a,b,c) = (1,2,1/2)$ sont donc des réels tels que $V$ soit une
    fonction de Liapounov.
  \item
    Prenons, $(a,b,c) = (1,2,1/2)$.
    Comme $V$ est un polynôme, $V$ est continu et sa dérivée est continue.
    $f$ qui est manifestement défini par
    $f(x,y,z) = (2y(z-1), -x(z-1), -z^3)$ a une jacobienne valant
    \[ Df(x,y,z) =
    \begin{pmatrix}
      0 & 2(z-1) & 2y\\
      -(z-1) & 0 & -x\\
      0 & 0 & -z^2
    \end{pmatrix}
    \]
    qui est continue donc $f$ est localement lipschitzienne.
    On a vu que $V(x,y,z)$ était décroissante le long d'une courbe
    intégrale $u = (x,y,z)$.
    De plus, on voit que comme $a$, $b$ et $c$ sont positifs,
    $V(x,y,z) > 0$ $\forall x,y,z \in \mathbb{R}^3\setminus\{(0,0,0)\}$.
    On a donc $V(x) \geq V(0,0,0)$ car $V(0,0,0) = 0$.
    $(0,0,0)$ est donc un équilibre stable.
  \item
    Le $V$ trouvé plus haut ne peut pas fonctionner ici
    car $V \circ u$ n'est pas strictement décroissant pour tout
    $u \in \Omega \setminus \{u_0\}$.
    En effet, $(V \circ u)' = -2cz^4$
    est nul pour tout $u = (x,y,0)$.
    Démontrons le par la définition.
    Pour cela, il nous faudra un peut d'intuition.
    Comme on avait $(V \circ u)' = -2cz^4$, on est tenté de prendre $z = 0$
    car ça rendrait $V \circ u$ constant.
    Cherchons donc une solution avec $z = 0$, on a
    \begin{align*}
      x' & = -2x\\
      y' & = x
    \end{align*}
    d'où une solution possible
    $(x,y,z) = (x_0\cos(\sqrt{2}t),x_0/\sqrt{2}\sin(\sqrt{2}t),0)$ liée
    à la condition initiale $u_0 = (x_0,0,0)$.
    On voit donc que quelque quel que soit $\delta > 0$,
    en prenant $0 < x_0 < \delta$,
    on voit que la limite de $u$ quand $t$ tend vers l'infini ne converge pas,
    $(0,0,0)$ n'est donc pas un équilibre asymptotiquement stable.
\end{enumerate}

\subsection*{4.4}
$f$ définie par $f(x) = -x^3$ est localement lipschitzienne car sa dérivée
$-3x^2$ est continue.
$V(x) = x^2$ est de classe $C^1$ et
$(V \circ x)' = V'(x)x' = -2x^4 \leq 0$ pour tout $x$ donc $V \circ x$
est décroissante.
De plus on voit que $V(x) = x^2 > 0$ pour tout $x \neq 0$.
L'origine est donc un équilibre stable.

\section{Problèmes aux limites pour les
systèmes d'équations différentielles linéaires}

\subsection*{5.3}
\begin{enumerate}
  \item
    Reformulons le problème comme suit
    \begin{align*}
    \begin{pmatrix}
      u_1\\u_2
    \end{pmatrix}' & =
    \begin{pmatrix}
      0 & 1\\-\lambda^2 & 0
    \end{pmatrix}
    \begin{pmatrix}
      u_1\\u_2
    \end{pmatrix}
    +
    \begin{pmatrix}
      0\\f
    \end{pmatrix}\\
    0 & =  u_2(1) - u_1(1)\\
    u_1(-1) - u_2(-1) & = 0.
    \end{align*}

    Ce système possède une solution
    ssi $\forall v: [-1;1] \to \mathbb{R}^2$ tel que
    \[\begin{pmatrix}
      v_1\\v_2
    \end{pmatrix}' =
    \begin{pmatrix}
      0 & \lambda^2\\-1 & 0
    \end{pmatrix}
    \begin{pmatrix}v_1\\v_2
    \end{pmatrix}\]

    et $(\alpha|v(-1)) = (\beta|v(1))$ $\forall \alpha,\beta \in\mathbb{R}^2$
    tels que $B_{-1}(\alpha) = B_1(\beta)$
    avec $B_{-1}[\alpha] =
    \begin{pmatrix}
      0\\\alpha_1-\alpha_2
    \end{pmatrix}$ et
    $B_1 =
    \begin{pmatrix}
      \beta_2-\beta_1\\0
    \end{pmatrix}$
    on a
    \[ \int_{-1}^1 f(s)v_2(s) \dif s = 0 \].


    Donc $\alpha_1 = \alpha_2$ et $\beta_1 = \beta_2$.
    Les conditions aux limites pour $v$ deviennent
    \[\alpha_1(v_1(-1) + v_2(-1)) = \beta_1(v_1(1) + v_2(1))\]
    $\forall \alpha_1,\beta_1 \in\mathbb{R}$.

    On a 2 conditions aux limites linéairement indépendantes
    \begin{align*}
      v_1(-1) + v_2(-1) & = 0\\
      v_1(1) + v_2(1) & = 0.
    \end{align*}

    \paragraph{Résolution}
    $v_2'' = -v_1' = -\lambda^2 v_2$
    Si $\lambda \neq 0$,
    $v_2(t) = A \cos(\lambda t) + B\sin(\lambda t)$ où $A, B \in \mathbb{R}$
    \begin{align*}
      v_1(t) & = -v_2'(t)\\
      & = A\lambda\sin(\lambda t) - B\lambda\cos(\lambda t)
    \end{align*}
    Si on explicite les conditions aux limites, on a
    \begin{align}
      \label{eq:cl1}
      A \cos\lambda - B \sin\lambda - A\lambda \sin\lambda - B\lambda\cos\lambda & = 0\\
      \label{eq:cl2}
      A \cos\lambda + B \sin\lambda + A\lambda \sin\lambda - B\lambda\cos\lambda & = 0.
    \end{align}
    Par $\eqref{eq:cl1} + \eqref{eq:cl2}$,
    \[ 2A\cos\lambda - 2B\lambda\cos\lambda = 0 \]
    et par $\eqref{eq:cl1} - \eqref{eq:cl2}$,
    \[ 2B\sin\lambda + 2A\lambda\sin\lambda = 0 \]
    d'où
    \begin{align*}
      \cos\lambda (A - B\lambda) & = 0\\
      \sin\lambda (B + A\lambda) & = 0.
    \end{align*}

    On doit considérer ici plusieurs cas
    \begin{itemize}
      \item Si $\lambda \neq k\frac{\pi}{2}$, $k \in \mathbb{Z}$,
        $A - B\lambda = 0$ et $B + A\lambda = 0$ donc $A = B = 0$.

      \item Si $\lambda = k\pi$, $k \in \mathbb{Z}_0$, $A = B\lambda$,
        donc
        \[ 0 = \int_{-1}^1 f(t) (\lambda \cos(\lambda t) + \sin(\lambda t)) \dif t. \]

      \item Si $\lambda = \frac{\pi}{2} + k\pi$, $k \in \mathbb{Z}$, $B = -A\lambda$,
        donc
        \[ 0 = \int_{-1}^1 f(t) (\cos(\lambda t) - \lambda\sin(\lambda t)) \dif t. \]
    \end{itemize}

    Si $\lambda = 0$,
    \begin{align*}
      v_2(t) & = A + Bt\\
      v_1(t) & = -B
    \end{align*}
    et par les conditions aux limites
    \begin{align*}
      A + B - B & = 0\\
      A - B - B & = 0.
    \end{align*}
    Donc $A = B = 0$, du coup, pas de contrainte sur $f$.
\end{enumerate}

\end{document}
